[A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play](https://doi.org/10.1126/science.aar6404)



可以講係近年最大嘅突破之一

但都好難運用到其他game入邊

Alphazero 唔依賴額外嘅先驗知識，只有基本嘅規則，通過MCTS搜索自博弈去提升性能，確實係勁

但缺點都唔少

1.需要超大嘅計算資源，MCTS模擬博弈嘅天然問題

2.如果環境有一定嘅隨機性，或者係喺連續空間下，好難用得到，棋類遊戲因爲規則簡單，動作簡單，雖然空間好大，但都比較容易模擬仿真



所以如果要遷移其他嘅話，大概就係model-based嗰套，先有得去模擬仿真

