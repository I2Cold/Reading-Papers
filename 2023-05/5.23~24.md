[Frustratingly Easy Regularization on Representation Can Boost Deep Reinforcement Learning](https://openaccess.thecvf.com/content/CVPR2023/html/He_Frustratingly_Easy_Regularization_on_Representation_Can_Boost_Deep_Reinforcement_Learning_CVPR_2023_paper.html)



將Q睇成encoder->representation + linear layer->target嘅組成，之前都有人提出過，而呢篇就更加深入地剖析噉樣分解得到嘅representation有乜嘢弊端



其實我覺得呢個loss都算auxiliary task嘅一種，用於提升distinguishable representation

而有收斂性證明同埋比較簡單係加分項，而且同其他representation learning嘅方法可兼容，同時可用於state and pixel task



