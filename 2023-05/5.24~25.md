[Reinforcement Learning-Based Black-Box Model Inversion Attacks](https://arxiv.org/abs/2304.04625)



比較有意思嘅領域——從 model 中重建用於訓練嘅隱私敏感數據，which我自己之前係冇考慮過嘅，所以實牙實齒話可以做到唔泄露……well，服務提供商可以唔泄露，but 如果係隱藏喺公開 model 入邊嘅數據呢（white-box）？ or 隱藏喺輸出結果+置信度呢（black-box）？甚至於直接喺輸出結果入邊（label-only）？

> The white-box attacks can access all parameters of the model. The black-box attacks can access soft inference results consisting of confidence scores, and the label-only attacks only can access inference results in hard label forms.



而且都幾interesting，我哋成日聽將Actor-Critics類比爲Generator-Discriminator，而兩者結合埋一齊，都有搞作。構建成 MDP 嚟訓練，充分探索成個空間，妙哉妙哉，不過呢篇GAN同AC係分開訓練，所以可以講係引入AC嚟improve





都有其他work係兩者結合，例如呢篇

[AC-SUM-GAN: Connecting Actor-Critic and Generative Adversarial Networks for Unsupervised Video Summarization](https://paperswithcode.com/paper/ac-sum-gan-connecting-actor-critic-and)

呢篇2020嘅文章將主要嘅發展歷史都講咗，比較詳盡。而且係同時訓練AC同GAN，合作完成同一個任務

而且abalation證明AC嘅引入對性能有極大嘅提升



